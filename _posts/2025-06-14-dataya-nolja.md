---
created: 2025-06-14
title: 2025 데이터야 놀자
layout: post
tags: [세미나, 데이터]
category: 데이터
---

지인의 소개로 '데이터야 놀자' 세미나에 다녀왔습니다. 유튜브에서 우연히 접한 뒤로 관심 있게 보던 세미나라, 실제로 참석할 수 있어 무척 기대가 컸습니다:) 이런 좋은 기회를 준 J에게 다시 한 번 감사하며, 제가 인상 깊게 들은 부분을 제 경험과 함께 풀어보려합니다.

![dataya-nolja](https://github.com/kida0/kida0.github.io/blob/main/assets/images/123.png?raw=true)


## 성과는 우연이 아니다: 데이터를 읽고 설득하는 마케터의 전략

첫 번째 세션에서는 게임 업계에서 마케팅을 담당하는 발표자님이, 데이터를 기반으로 신규/기존/복귀 북미 유저를 모두 아우를 수 있는 마케팅 전략을 어떻게 수립했는지 사례를 공유해주셨습니다.

우선 유저의 만족도를 파악하기 위해 **앱 리뷰를 수집하고 키워드 분석을 진행**했는데요. 긍정적인 키워드들을 **캐릭터 커스터마이징, BGM, IP, 스토리/세계관, 그래픽**의 5개 카테고리로 분류해 **어떤 요소가 유저에게 가장 강한 인상을 주었는지**를 확인했다고 합니다. 이후에는 설문을 통해 수집한 유저의 VoC(Voice of Customer)와 교차 검증을 진행했습니다.

당시 북미 시장에서는 모바일 기반 인터렉션 콘텐츠가 인기였다고 합니다. 분석 결과를 바탕으로, 상위 긍정 카테고리를 타로 이벤트 형태로 기획하여 마케팅을 진행하고, 다른 이벤트 대비 참여율이 3배 높을 정도로 성공적인 호응을 얻었다고 합니다.

세션 후 Q&A에서 인상 깊었던 점은, 많은 참가자들이 **지표의 정의와 선정 이유**에 관심을 보였다는 점입니다. 예를 들어, 발표자님이 마케팅 실행 후 'D1 리텐션'을 주요 지표로 활용했다고 하자, '왜 D1을 봤는지', '게임 업계에서는 D1이 특히 중요한지' 같은 질문들이 이어졌습니다.

이런 질문들을 보면서, (너무 당연하게 생각되는 방법이어도) '왜 이 지표를 쓰는가'를 스스로 생각해보는 습관이 중요하다는 점을 다시금 느꼈습니다.


## 로그 데이터로 사용자 이탈 뜯어보기: 행동 단위로 퍼널을 만들어본 PM의 분석기

두 번째 세션의 발표자님은 용달 중개 서비스에서 사용자의 이탈 문제를 어떻게 분석했는지 공유해주셨습니다. 이 서비스는 소셜 앱처럼 자주 사용하는 형태는 아니지만, 한 번 사용할 때 입력해야 할 정보가 많아 이탈이 많이 발생했다고 합니다. 프로젝트의 목표는 **사용자 이탈 지점을 명확히 식별하고, 그 원인을 정량적으로 파악하는 것**이었습니다.

서비스 퍼널을 분석할 때 흔히 마주치는 문제는 사용 흐름이 단선형이 아닌 다양성을 띤다는 점입니다. 예를 들어, 같은 기능을 사용하더라도 어떤 사용자는 이름을 먼저 입력하고, 어떤 사용자는 주소를 먼저 입력하는 등 경로가 다를 수 있습니다.

발표자님은 이를 해결하기 위해 **프로세스 마이닝 기법**을 도입했습니다. 이 기법을 활용하면 실제 사용자가 어떤 행동 흐름(variant)을 통해 앱을 이용했고, 어떤 지점에서 이탈했는지를 시각적으로 분석할 수 있습니다. 

![process-mining](https://blog.bizspring.co.kr/wp-content/uploads/2024/10/process-mining1.png){: width="40%" height="40%"}

위 그림에서의 행동 흐름을 아래와 같이 정리할 수 있습니다.

|행동 흐름(variant)|유저 수|
|---|---|
|이름 입력 > 주소 입력 > 이탈|20명|
|이름 입력 > 주소 입력 > 결제 방식 등록 > 이탈|50명|
|주소 입력 > 이름 입력 > 주소 수정 > 이탈|5명|

흥미로운 점은, 겉보기에는 단순한 앱 구조임에도 약 **3,000개의 서로 다른 행동 흐름**이 존재했다는 점입니다. 이는 우리가 흔히 사용하는 **퍼널 분석이 실제 사용자 행동을 얼마나 단순화하고 있는지**, 그리고 **사용자의 실제 행동 흐름이 얼마나 다양한지**를 보여줍니다.

무엇보다 이러한 분석을 통해 단순히 이탈율이나 전환율 같은 지표에 대한 인사이트를 넘어, 주소 입력에 소요된 시간, 결제 수단 입력 전 반복된 단계, 특정 입력 항목에서 머문 시간과 같은 사용자 경험의 병목 지점을 정량적으로 파악한 점이 인상깊었습니다.

발표자님은 여기서 한 걸음 더 나아가, 사용자가 '어려움을 겪고 있다'는 상태를 어떻게 정의할 수 있을지에 주목했습니다. 이를 위해 **'어려움'에 대한 위해 조작적 정의(operational definition)를 내렸는데요**, 조작적 정의란 행복을 웃는 횟수로, 스트레스를 간식 섭취 빈도로 측정하듯, 추상적인 개념을 구체적이고 측정 가능하게 정의하는 방법을 말합니다.

그럼 '사용자가 어려움을 겪는다'는 어떻게 정의할 수 있을까요? 발표자님은 (1)이탈 직전에 마지막으로 한 행동, (2)반복적으로 한 행동, (3)가장 긴 시간이 소요된 행동을 복합적으로 고려하여 '어려움' 정의했다고 합니다. 이러한 정의를 통해 사용자 행동을 다시 분석한 결과, 기존의 퍼널 분석만으로는 놓쳤던 진짜 불편한 지점을 구체적으로 포착하고 개선할 수 있었다고 합니다.


### 9년차 데이터 분석가가 말아주는 초기 스타트업 적응기

마지막으로 소개할 세션은 제가 이번 세미나에서 제가 가장 인상 깊게 들은 발표입니다. 시니어 데이터 분석가로 일하고 계신 발표자님은 초기 스타트업에 합류해 데이터 업무를 어떻게 구축하고 운영해왔는지, 경험을 풀어주셨습니다. 발표를 들으며 과거에 제가 직접 했던 선택들과 비교해 보게 되었고, 부족했던 점들을 되돌아보며 '나중에 나도 저런 문제를 더 잘 풀 수 있는 사람이 되고 싶다'는 생각을 많이 했습니다.

**1  데이터 분석 인프라 만들기**
대부분의 스타트업은 분석 환경과 서비스 운영 환경이 분리되어 있지 않아, 운영 데이터와 로그 데이터를 통합적으로 보기 어렵습니다. 특히 스타트업은 자원(금전적/인적)이 제한되어 있어 기술 선택에서도 비용과 운영 효율성을 함께 고려해야 합니다. 예를 들어, 단순히 기술적으로 더 좋아 보인다는 이유로 복잡한 툴을 도입하는 것이 아니라, 실제 문제를 정확히 정의하고 그에 맞는 적절한 도구를 고르는 것이 중요합니다. 

실제로 발표자님은 Airflow 같은 툴 대신 AWS Lambda와 같은 간단한 서버리스 서비스를 활용하여 데이터 분석 인프라를 만들었다고 합니다. 요즘처럼 제품 분석 툴이나 대시보드 툴이 넘쳐나는 시대에 어떤 도구를 도입할지도, 단순한 기능 비교가 아니라 운영 부담과 비용 효율성을 모두 고려해야 한다는 점에 깊이 공감했습니다.

**2 로그 택소노미(Taxonomy) 만들기**
스타트업 초기에는 로그 데이터가 정리되지 않은 채 쌓이기 쉬운데, 수집하는 데이터의 이름을 어떻게 지을지에 대한 내부 합의가 없다면 곧바로 혼란으로 이어질 수 있습니다. 예를 들어, 버튼 클릭이라는 하나의 행동도 ClickButton, click_button, click_btn처럼 다양한 방식으로 기록될 수 있습니다. 데이터가 이런 식으로 제각각 쌓이기 시작하면 나중에 데이터를 처리에서 과정에서 큰 어려움을 겪게 됩니다. 그래서 초기 단계에서 네이밍 컨벤션을 명확히 정하고, 로그는 규칙이기 때문에 일관되게 지켜야 한다는 점을 강조하셨습니다.

**3 NSM(North Star Metric, 북극성 지표) 정하기**
빠르게 변화하는 시장에 발빠르게 대응하기 위해 스타트업에게는 전사적으로 하나의 방향성을 공유하는 것이 중요합니다. 이때 중심이 되는 지표를 NSM 또는 OMTM(One Metric That Matters)이라고 부릅니다. NSM을 설정할 때는 후행 지표보다는 행동을 유도하는 선행 지표를 선택하는 것이 중요합니다. 예를 들어, 광고 수익을 극대화하는 것이 목표라면, 광고 수익 자체보다는 트래픽을 나타낼 수 있는 DAU를 NSM으로 삼는 것이 좋습니다. 

다만, 어떤 프로젝트의 지표를 어디까지, 얼마만큼 볼 것인가는 경험적인 부분으로 여전히 어려운 문제입니다. NSM과 같이 단 하나의 지표를 바라보는 것은 리스크가 있기 때문에, 보조 지표나 가드레일 지표를 같이 보는 것 또한 중요하다고 생각합니다.

**4 데이터 리터러시 쌓아가기**
'활성 유저'란 누구일까요? '인게이지먼트가 상승했다'는 또 무슨 말일까요? 이렇게 다소 모호할 수 있는 표현들을 조직 내에서 명확히 정의하고 합의하는 과정이 필요합니다. 또한 발표자님은 의욕이 많은 신입 때 온보딩을 잘 하는 것(~~= 빡센 가스라이팅~~)이 중요하다고 농담처럼 이야기하시기도 했습니다.

'데이터 성숙도'를 어떻게 조직 내에 정착시키고, 데이터 기반 의사결정을 일상화할 수 있을지에 대한 고민은 분석가라면 누구나 부딪히게 되는 주제인 것 같습니다. 이 문제에 대한 이상적인 접근 방법은 '그로스해킹'의 저자인 양승화님의 [데이터가 흐르는 조직 만들기](https://www.youtube.com/watch?v=lG6gJGmEbew) 강연에서 좀 더 자세히 확인하실 수 있습니다. 데이터 리터러시는 한 순간 해결할 수 있는 문제가 아니라, 지속적으로 고민하고, 다듬고, 공유해 나가는 문제인 것 같습니다.

이 외에도 좋은 세션이 많았지만, 자리가 부족해 서서 듣는 바람에 정리를 놓친 부분들이 있습니다. 관심 있는 분들은 유튜브 채널 [2025 데이터야 놀자](https://www.youtube.com/@datayanolja/videos)에서 전체 영상을 확인하실 수 있습니다.


## 만약에 내가 발표를 한다면?
요즘 들어 학습하고, 실무에 적용하며 경험하고, 실패와 성공을 통해 얻은 인사이트를 공유하는 사이클이 무척 소중하게 느껴집니다. 그리고 이런 경험의 공유가 저에게는 일의 원동력 중 하나이기 때문에, 나중에 좋은 프로젝트를 하게 된다면 발표자로서 제 경험을 나누어보고 싶습니다. 개인적으로 세미나를 들으면서 좋은 발표를 준비하는 방법에 대해 생각한 부분을 정리하며 후기를 마무리해보겠습니다.

1. 사람들이 궁금해하는 것은 이론 그 자체가 아니라, ‘그 이론을 통해 실제 문제를 어떻게 풀어냈는가’에 대한 경험이다. 이론은 책이나 영상 등 다른 자료를 통해 공부할 수 있다.
2. 지표나 개념에 대해 주석을 달아주면 좋다. 실제로 개발자 친구가 ROAS, CAC 같은 용어를 보고 이해를 어려워했다.
3. 한 세션(20~30분)이 길어 보이지만, 소개와 마무리 시간을 제외하면 결코 길지 않다. 짧은 시간 안에 나의 경험을 어떻게 밀도 있게 전달할 수 있을지 미리 구조화해보자.
4. 폰트 사이즈는 생각보다 크게 써도 괜찮다. 특히 이미지나 그래프 속 폰트가 작으면 범례나 축 레이블이 잘 보이지 않아 청중 입장에서 이해하기 어려울 수 있다.
